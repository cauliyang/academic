---
# Documentation: https://wowchemy.com/docs/managing-content/

title: "Face Recognition"
subtitle: "å®ç°åœ¨è§†é¢‘ä¸­è¯†åˆ«ç‰¹å®šäººç‰©å¹¶è·å–æ—¶é—´è®°å½•"
summary: "æœ¬ç¯‡è®°å½•æœ€è¿‘è¾¹å­¦è¾¹åšçš„ä¸€ä¸ªæ— è¶£çš„å°é¡¹ç›®ï¼Œç”¨äºå¸®åŠ©åŒçª—æé«˜å·¥ä½œæ•ˆç‡"
authors: ['admin']
tags: ['Computer Vision']
categories: ['Deep Learning']
date: 2021-04-05T12:54:10+08:00
lastmod: 2021-04-05T12:54:10+08:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: 'Image credit: [**Unsplash**](https://unsplash.com/)'
  focal_point: ""
  placement: 0
  preview_only: true

# links:
# - name: Custom Link
#   url: http://example.org

url_pdf: ''
url_code: ''
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: ''
url_source: ''
url_video: ''

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
---

{{< toc  >}}

<style>
img{
    width: 70%;
    padding-left: 14%;
    height: 50%
}
</style>


## 1. å‡†å¤‡å·¥ä½œ

ä½¿ç”¨**Python**å®ç°éœ€æ±‚ï¼Œç¯å¢ƒéœ€æ±‚æ¯”è¾ƒä¸¥è‹›ï¼Œæ‰€éœ€è¦çš„ä¸»è¦ä¾èµ–ï¼š

**Requirements**
- **dlib** ç”±C++ç¼–å†™ï¼Œæä¾›äº†å’Œæœºå™¨å­¦ä¹ ã€æ•°å€¼è®¡ç®—ã€å›¾æ¨¡å‹ç®—æ³•ã€å›¾åƒå¤„ç†ç­‰é¢†åŸŸç›¸å…³çš„ä¸€ç³»åˆ—åŠŸèƒ½
- **face-recognition** å·²ç»ç»è¿‡è®­ç»ƒæˆç†Ÿçš„è¯†åˆ«äººè„¸çš„å·¥å…·
- **imutils** ç”¨æ¥æ“ä½œç³»ç»Ÿæ–‡ä»¶å’Œæ–‡ä»¶å¤¹ 
- **Opencv**æ˜¯ç”¨æ¥æ“ä½œè§†é¢‘æµï¼Œå¹¶å°†è§†é¢‘æµè½¬æ¢æ ¼å¼

### 1.1 ç¯å¢ƒæ­å»º   

1. é€šè¿‡pipè¿›è¡Œå®‰è£…ï¼Œåœ¨ä½¿ç”¨pipè¿›è¡Œå®‰è£…æ—¶ï¼Œåº”è¯¥æ³¨æ„åˆ‡æ¢åˆ°å›½å†…æºè¿›è¡Œä¸‹è½½ï¼Œæé«˜ä¸‹è½½é€Ÿåº¦ï¼Œä¸‹é¢åˆ†äº«ä¸€ä¸‹å½“å‰å›½å†…çš„pipæºï¼š
   
    + é˜¿é‡Œäº‘ https://mirrors.aliyun.com/pypi/simple/
    + ä¸­å›½ç§‘æŠ€å¤§å­¦ https://pypi.mirrors.ustc.edu.cn/simple/
    + è±†ç“£ http://pypi.douban.com/simple/
    + æ¸…åå¤§å­¦ https://pypi.tuna.tsinghua.edu.cn/simple/
    + ä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦ http://pypi.mirrors.ustc.edu.cn/simple/   

2. é€šè¿‡Anacondaè¿›è¡Œå®‰è£…ï¼Œä½†æ˜¯éœ€è¦æ³¨æ„çš„æ˜¯åœ¨Anacondaçš„èµ„æºä¸­å¹¶æ²¡æœ‰**face-recognition**ï¼Œéœ€è¦ä½¿ç”¨pipå®‰è£…ã€‚åœ¨å®‰è£…ä¸­å¯èƒ½é‡åˆ°é—®é¢˜å› æ­¤åœ¨æ­¤åˆ†äº«æˆ‘çš„ç¯å¢ƒï¼Œåˆ†åˆ«åœ¨Windowså’ŒMacç¯å¢ƒä¸‹è¿›è¡Œæµ‹è¯•ã€‚

- Mac ç¯å¢ƒ
  
    - Python 3.8
    - dlib 19.20.0
    - cmake 3.18.0
    - face-recognition 1.3.0
    - imutils 0.5.3 

- Windows ç¯å¢ƒ
  
    - Python 3.6
    - dlib 19.7.0
    - cmake 3.18.0
    - face-recognition 1.3.0
    -  imutils 0.5.3   
  
åœ¨Windows ç¯å¢ƒä¸­å®‰è£…**dlib**å¦‚æœé€šè¿‡pipå®‰è£…é‡åˆ°é—®é¢˜ï¼Œå¯ä»¥ç›´æ¥ä¸‹è½½å¯¹åº”ç‰ˆæœ¬çš„[**Whl**æ–‡ä»¶](https://pypi.org/simple/dlib/)ï¼Œä½¿ç”¨`pip install dlib-19.7.0-cp36-cp36m-win_amd64.whl`å‘½ä»¤è¿›è¡Œå®‰è£…ã€‚    

## 2. ç´ æå±•ç¤º  

ç¯å¢ƒæ­å»ºå®Œæ¯•åï¼Œ**è¯¥é¡¹ç›®çš„ç›®çš„æ˜¯æ•æ‰äººç‰©åœ¨è§†é¢‘ä¸­å‡ºç°å¹¶è®°å½•ç›¸åº”æ—¶é—´**ã€‚é¦–å…ˆè®©æˆ‘ä»¬ç†Ÿæ‚‰ä¸€ä¸‹è¯¥å°é¡¹ç›®çš„æµ‹è¯•ç´ æï¼š  

  - ç›®æ ‡äººç‰©çš„ç…§ç‰‡
  - å­˜åœ¨ç›®æ ‡äººç‰©çš„æµ‹è¯•è§†é¢‘
  
### 2.1 ç›®æ ‡äººç‰©çš„ç…§ç‰‡ 


1.![](https://cdn.jsdelivr.net/gh/cauliyang/blog-image@main//img/1595310450018.png)

2.![](https://cdn.jsdelivr.net/gh/cauliyang/blog-image@main//img/1595310499443.png)


   
åœ¨æœ¬é¡¹ç›®çš„éœ€æ±‚ä¸­åªå­˜åœ¨ä¸€ä¸ªç›®äººç‰©ï¼Œç…§ç‰‡æ•°é‡è¶Šå¤šè¶Šå¥½ï¼Œæ•°é‡åœ¨30-80ä¹‹é—´å°±å¯ä»¥åŸºæœ¬å®ç°è¯¯å·®åº¦è¾ƒä½çš„è¯†åˆ«ç²¾åº¦ï¼Œä½†æ˜¯éœ€è¦æ³¨æ„çš„æ˜¯ç…§ç‰‡ä¸­åº”åªå­˜åœ¨ä¸€äººï¼Œä¸”è¡¨æƒ…åº”è¯¥å°½é‡ä¸°å¯Œï¼Œç…§ç‰‡ä¸èƒ½è¿‡äºå•ä¸€ã€‚

### 2.2 æµ‹è¯•è§†é¢‘

![](https://cdn.jsdelivr.net/gh/cauliyang/blog-image@main//img/1595314710081.gif)

## 3. å®ç°æµç¨‹  

åœ¨è§†é¢‘ä¸­å®ç°ç‰¹å®šäººç‰©çš„äººè„¸è¯†åˆ«ï¼Œéœ€è¦ä¸»è¦ä¸¤ä¸ªæ­¥éª¤ï¼š   

1. å¯¹ç´ æä¸­ç…§ç‰‡è¿›è¡Œç¼–ç ï¼Œå°†æ¯ä¸€å¼ ç…§ç‰‡è½¬æ¢ä¸ºä¸€ä¸ªå«æœ‰128ä¸ªå…ƒç´ çš„1ç»´æ•°ç»„     

![](https://cdn.jsdelivr.net/gh/cauliyang/blog-image@main//img/1595315291836.png)

2. è¯†åˆ«è§†é¢‘ä¸­å¯¹äººè„¸ï¼Œè½¬æ¢ä¸ºæ•°ç»„ä¸ç›®æ ‡æ•°ç»„è¿›è¡Œæ¯”å¯¹ï¼Œç¡®å®šæ˜¯å¦åŒ¹é…ï¼Œå®Œæˆè¯†åˆ«ã€‚

![](https://cdn.jsdelivr.net/gh/cauliyang/blog-image@main//img/1595316395676.png)

### 3.1 ç¼–ç ç…§ç‰‡  

```python

# å¯¼å…¥æ¨¡å—
from imutils import paths # æ“ä½œæ–‡ä»¶
import face_recognition   # è¯†åˆ«äººè„¸å¹¶ç¼–ç 
import pickle  # ä½¿ç”¨pickleæ–‡ä»¶å½¢å¼å‚¨å­˜èŠ‚çœç©ºé—´
import cv2     # æ“ä½œè§†é¢‘æµ

# è·å–ç…§ç‰‡
print("[INFO] quantifying faces...")
imagePaths = list(paths.list_images("./dataset")) # datasetä¸ºå‚¨å­˜ç…§ç‰‡æ–‡ä»¶å¤¹

# åˆå§‹åŒ–å‚¨å­˜æ‰€æœ‰ç…§ç‰‡ç¼–ç 
knownEncodings = []

# éå†æ¯å¼ ç…§ç‰‡å¹¶ç¼–ç 
for (i, imagePath) in enumerate(imagePaths):

    print("[INFO] processing image {}/{}".format(i + 1, len(imagePaths)))

    # åŠ è½½å›¾ç‰‡ï¼Œè½¬æ¢ä¸ºRGBæ¨¡å¼
    image = cv2.imread(imagePath)
    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # è¯†åˆ«äººè„¸å¹¶è¿”å›ä½ç½®
    boxes = face_recognition.face_locations(rgb,
                                            model='hog' # model å¯ä»¥é€‰æ‹© cnn æˆ– hog
                                            )

    # ç¼–ç ç…§ç‰‡å¹¶å‚¨å­˜
    encodings = face_recognition.face_encodings(rgb, boxes)
    knownEncodings.append(encoding)

# å†™å…¥ç…§ç‰‡çš„ç¼–ç 
print("[INFO] serializing encodings...")
data = {"encodings.pickle": knownEncodings}
with open('encoding_face.pickle', "wb") as f:
    f.write(pickle.dumps(data))

```

åœ¨ç¼–ç ç…§ç‰‡æ—¶è¦æ³¨æ„æ¨¡å¼çš„é€‰æ‹©ï¼š

- å¦‚æœä½ æœ‰GPUï¼Œå¯ä»¥é€‰æ‹©å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ï¼Œå› ä¸ºè¦æ¶ˆè€—å¤§é‡çš„è®¡ç®—åŠ›ã€‚

- å¦‚æœä½ å’Œæˆ‘ä¸€æ ·ä½¿ç”¨CPUï¼Œé€‰æ‹©æ–¹å‘æ¢¯åº¦ç›´æ–¹å›¾æ–¹æ³•ï¼ˆHOGï¼‰ï¼Œå¤§å¤§åœ°æé«˜è®¡ç®—é€Ÿåº¦ï¼Œå¤„ç†30å¼ ç…§ç‰‡å¤§çº¦æ¶ˆè€—3-5åˆ†é’Ÿã€‚

å°†æ‰€æœ‰ç…§ç‰‡ç¼–ç å®Œæˆåï¼Œç»“æœæ–‡ä»¶å¯ä»¥åœ¨åç»­ä¸åŒè§†é¢‘ä¸­ä¸€ç›´ä½¿ç”¨ï¼Œå¦‚æœè¦æ·»åŠ æ›´å¤šç…§ç‰‡è¿›è¡Œæ£€æµ‹ï¼Œé‚£ä¹ˆåº”è¯¥é‡æ–°è¿›è¡Œç¼–ç ã€‚æ­¤å¤–è¿˜å¯ä»¥é‡‡ç”¨å…è´¹çš„GPUä½¿ç”¨ä¾‹å¦‚[Google Colab](https://colab.research.google.com/)å’Œ[Kaggle](https://www.kaggle.com/)ã€‚

### 3.2 è§†é¢‘è¯†åˆ«

é‡‡ç”¨**Opencv**å¤„ç†è§†é¢‘æµï¼Œä¸€å¸§ä¸€å¸§è¿›è¡Œæ“ä½œã€‚

```python 

# å¯¼å…¥æ¨¡å—
from imutils import paths
import face_recognition
import imutils
import pickle
import time
import cv2
import os

# è®¾ç½®å…¨å±€å˜é‡ï¼Œä¸‹æ–‡å…·ä½“è§£é‡Š
THRESHOLD = 0.5       
FILTER_STANDARD = 0.6  
FRAME_STEP = 20                 


# è·å–ç›®æ ‡æ–‡ä»¶å¤¹ä¸­è§†é¢‘æ–‡ä»¶ï¼Œå¹¶åˆ¤æ–­æ ¼å¼
def get_files():
    return [
        file for file in paths.list_files('./videos/')
        if os.path.splitext(file)[1] in ['.mp4', '.avi', '.rmvb']
    ]

# è·å–æ—¶é—´æˆ³
def get_time_stamp(stream):
    '''
    stream: å·²è¯»å–çš„è§†é¢‘
    '''
    # è·å–æ—¶é—´ï¼Œå•ä½ä¸ºæ¯«ç§’ 1000æ¯«ç§’ = 1ç§’
    milliseconds = stream.get(cv2.CAP_PROP_POS_MSEC)
    seconds = milliseconds // 1000
    milliseconds = milliseconds % 1000
    minutes = 0
    hours = 0

    if seconds >= 60:
        minutes = seconds // 60
        seconds = seconds % 60

    if minutes >= 60:
        hours = minutes // 60
        minutes = minutes % 60
    # è¿”å›æ—¶é—´æˆ³
    return f'{int(hours)}:{int(minutes)}:{int(seconds)}'

# å¤„ç†è§†é¢‘æµ
def worker(file, data, display=1):
    '''
    file: è§†é¢‘æ–‡ä»¶åœ°å€
    data: å·²ç»è¯»å–çš„ç¼–ç æ–‡ä»¶
    display: æ˜¯å¦å®æ—¶å±•ç¤ºè§†é¢‘å¤„ç†è¿‡ç¨‹ [0,1]ï¼Œ1ä¸ºå±•ç¤º
    '''
    # åˆ›å»ºç»“æœæ–‡ä»¶
    new_file = open(f'{file}.txt', 'w')
    # åˆå§‹åŒ–å½“å‰å¸§
    current_frame = 0
    # æ˜¾ç¤ºæ­£åœ¨å¤„ç†è§†é¢‘æ–‡ä»¶
    print(f"[INFO] processing video {file}...")
    # è¯»å–è§†é¢‘
    stream = cv2.VideoCapture(file)
    
    # éå†è§†é¢‘ä¸­æ¯ä¸€å¸§è¿›è¡Œå¤„ç†
    grabbed = True
    while grabbed:
        # è·å–ä¸€å¸§
        (grabbed, frame) = stream.read()
        # åˆ¤æ–­æ˜¯å¦è·³å¸§
        if current_frame % FRAME_STEP == 0:
            # è½¬æ¢ä¸ºRGBæ¨¡å¼å¹¶æ”¹å˜å¸§å¤§å°
            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            rgb = imutils.resize(frame, width=750)
            # è·å–ç¼©æ”¾æ¯”ä¾‹
            r = frame.shape[1] / float(rgb.shape[1])
            # è¯†åˆ«æ¯ä¸€å¸§ä¸­çš„äººè„¸ model å¯ä»¥é€‰æ‹© hog æˆ– cnn
            boxes = face_recognition.face_locations(rgb, model='hog')
            # å¯¹æ¯ä¸€å¸§ä¸­äººè„¸è¿›è¡Œç¼–ç 
            encodings = face_recognition.face_encodings(rgb, boxes)
            
            # åˆå§‹åŒ–ä¿å­˜æ‰€è¯†åˆ«äººå§“å
            names = []

            # å°†æ¯ä¸€å¸§ä¸­çš„æ‰€æœ‰è¢«ç¼–ç çš„äººè„¸ä¸ç›®æ ‡è¿›è¡Œæ¯”å¯¹
            # æ¯ä¸€ä¸ª encoding éƒ½æ˜¯ä¸€å¼ è¢«ç¼–ç çš„äººè„¸
            for encoding in encodings:
                # å’Œç›®æ ‡æ‰€æœ‰è¢«ç¼–ç çš„ç…§ç‰‡è¿›è¡Œæ¯”å¯¹
                matches = face_recognition.compare_faces(data["encodings"],
                                                         encoding,
                                                         tolerance=THRESHOLD)
                # åˆå§‹åŒ–å§“å
                name = "Unknown"
                # è·å–è§†é¢‘ä¸­äººè„¸åŒ¹é…ç›®æ ‡æ‰€æœ‰ç…§ç‰‡çš„æ¯”ä¾‹
                true_value = (sum(matches) / len(data['encodings']))
                # æ»¡è¶³é˜ˆå€¼åˆ™è®¤å®šè¯†åˆ«æˆåŠŸ
                if true_value > FILTER_STANDARD:
                    name = 'Identified'
                names.append(name)

            # è·å–å½“å‰å¸§æ—¶é—´æˆ³
            time = get_time_stamp(stream)
            # æ ‡æ³¨æ¯ä¸€å¸§ä¸­çš„äººè„¸
            for ((top, right, bottom, left), name) in zip(boxes, names):
                # è®¡ç®—äººè„¸ä½ç½®
                top = int(top * r)
                right = int(right * r)
                bottom = int(bottom * r)
                left = int(left * r)

                # ç»˜å‡ºäººè„¸ä½ç½®
                cv2.rectangle(frame, (left, top), (right, bottom),
                    (0, 255, 0), 2)
                # æ·»åŠ æ¯ä¸€äººè„¸ç›¸åº”ä¿¡æ¯ï¼Œä¸»è¦æœ‰å§“åå’ŒåŒ¹é…ç›®æ ‡ç…§ç‰‡æ¯”ä¾‹
                y = top - 15 if top - 15 > 15 else top + 15
                cv2.putText(frame, f'{name} {true_value:.2f}', (left, y), cv2.FONT_HERSHEY_SIMPLEX,
                    0.75, (0, 255, 0), 2)
                # åˆ¤æ–­æ˜¯å¦è¿›è¡Œå®æ—¶æ’­æ”¾å¤„ç†
                if display > 0:
                    cv2.imshow("Frame", frame)
                    key = cv2.waitKey(1) & 0xFF

                # æŒ‰é”®qé€€å‡ºå¤„ç†
                if key == ord("q"):
                    break

            # å¦‚æœä¸€å¸§ä¸­æ˜¯å¦åŒ…å¥½ç›®æ ‡å¹¶å†™å…¥ç›¸åº”ä¿¡æ¯
            if 'Identified' in names:
                new_file.write(f'Identified\t{time}\n')
            else:
                new_file.write(f'Unknown\t{time}\n')
        # å¤„ç†ä¸‹ä¸€å¸§
        current_frame += 1

    # å…³é—­è§†é¢‘
    stream.release()


def main(encoding_file):
    data  = pickle.loads(open(encoding_file, "rb").read())
    for file in get_files():
        worker(file,data=data)

if __main__ == '__name__':
    main('./encodings.pickle')
```
åœ¨è§†é¢‘å®æ—¶å¤„ç†è¿‡ç¨‹ï¼š

![](https://cdn.jsdelivr.net/gh/cauliyang/blog-image@main//img/1595322861164.gif)

åœ¨è§†é¢‘å¤„ç†è¿‡ç¨‹ä¸­éœ€è¦æ³¨æ„çš„æ˜¯ä¸‰ä¸ªå…¨å±€å‚æ•°çš„é€‰æ‹©:

- **THRESHOLD** = 0.5           æ¯”è¾ƒè§†é¢‘ä¸­äººè„¸å’Œç›®æ ‡äººè„¸æ˜¯å¦ç›¸åŒï¼Œé»˜è®¤ä¸º0.6ï¼Œè¶Šå°è¶Šä¸¥æ ¼
- **FILTER_STANDARD** = 0.6  æ­¤é˜ˆå€¼ä¸ºè§†é¢‘ä¸­äººè„¸åŒ¹é…ç›®æ ‡æ‰€æœ‰ç…§ç‰‡çš„æ¯”ä¾‹ï¼Œè¶Šå¤§è¶Šä¸¥æ ¼
- **FRAME_STEP** = 20           è·³å¸§æ“ä½œï¼ŒåŠ å¿«è§†é¢‘å¤„ç†æ—¶é—´ï¼Œæœ¬è§†é¢‘ä¸­1Så¤§çº¦24å¸§ï¼Œæœ€å¥½ä¿è¯æ—¶é—´è¿ç»­ã€‚

å…¶æ¬¡ä»éœ€æ³¨æ„ç¼–ç è¿‡ç¨‹ä¸­æ–¹æ³•çš„é€‰æ‹©ï¼ŒCNNé€‚åˆæ¯”è¾ƒé€‚åˆGPUè®¡ç®—ã€‚


### 3.3 ç»“æœæ–‡ä»¶ 

å°†æ¯ä¸€å¸§çš„å¤„ç†ç»“æœå†™å…¥æ–‡ä»¶å½“ä¸­ï¼Œè¾“å‡ºç»“æœä¸­æœ‰å§“åå’Œå‡ºç°æ—¶é—´ï¼Œåç»­å¯ä»¥å¯¹æ ¹æ®ç»“æœå¯¹è§†é¢‘è¿›è¡Œå¤„ç†ã€‚

![](https://cdn.jsdelivr.net/gh/cauliyang/blog-image@main//img/1595323102132.png)

## 4. æ€»ç»“ 

### 4.1 å¯ä»¥æé«˜çš„åœ°æ–¹
åœ¨æ•´ä¸ªå®ç°è¿‡ç¨‹ä¸­éœ€è¦è€ƒè™‘å¯¹æ˜¯ç¡¬ä»¶å’Œè½¯ä»¶çš„ç»“åˆï¼Œæœ€å¤§ç¨‹åº¦åœ°æ»¡è¶³è¦è¾¾åˆ°çš„éœ€æ±‚ï¼Œåœ¨è¾¹å­¦è¾¹åšçš„è¿‡ç¨‹å½“ä¸­ï¼Œé€æ­¥æ‘¸ç´¢è™½ç„¶åˆæ­¥è§£å†³äº†é—®é¢˜ï¼Œä½†æ˜¯è¿˜æœ‰å¾ˆå¤šå¯ä»¥æ”¹æ­£å’Œæ·±æŒ–çš„åœ°æ–¹ã€‚

é¦–å…ˆæœ¬ç¯‡åšå®¢ä»£ç ä½¿ç”¨ç¡¬ç¼–ç ï¼Œè¿™æ ·å¥½å¤„æ˜¯æ–¹ä¾¿ä¸€äº›ï¼Œä½†æ˜¯ä¸é€‚åˆåˆ†äº«å’Œå¤ç°ï¼ŒåŒæ—¶å¯¹æ–‡ä»¶ç»“æ„æœ‰å¾ˆé«˜è¦æ±‚ï¼Œæˆ‘çš„æ–‡ä»¶ç»“æ„å¦‚ä¸‹ï¼š 

![](https://cdn.jsdelivr.net/gh/cauliyang/blog-image@main//img/1595323492839.png)


![](https://cdn.jsdelivr.net/gh/cauliyang/blog-image@main//img/1595323499909.png)

åç»­å¯ä»¥æ”¹ä¸ºå‘½ä»¤è¡Œè·å–å‚æ•°ï¼Œä»¤ä»£ç æ›´åŠ çµæ´»ã€‚å…¶æ¬¡å¯ä»¥ä¿®æ”¹ä»£ç ä½¿å…¶èƒ½å¤ŸåŒæ—¶å¤„ç†å¤šä¸ªè§†é¢‘ã€‚

åœ¨å…¨å±€å‚æ•°çš„é€‰æ‹©ä¹Ÿå­˜åœ¨äº›è®¸é—®é¢˜ï¼Œæˆ‘å¹¶æ²¡æœ‰æ‰¾åˆ°æœ€é€‚åˆçš„å‚æ•°ï¼Œå¯ä»¥ä»ç»“æœå›¾ç‰‡çœ‹å‡ºåœ¨è¯†åˆ«çš„è¿‡ç¨‹ä¸­å­˜åœ¨é”™è¯¯ï¼Œæˆ‘è®¤ä¸ºæœ‰ä¸¤ç§è§£å†³åŠæ³•ï¼š

1. å¢åŠ ç›®æ ‡ç¼–ç ç…§ç‰‡æ•°é‡ï¼Œåœ¨å®ç°å½“ä¸­ä½¿ç”¨å¤§çº¦40å¼ ç…§ç‰‡ï¼Œå¹¶ä¸”è¡¨æƒ…æ¯”è¾ƒå•ä¸€ï¼Œå¦‚æœåç»­å¯ä»¥ä¸°å¯Œç›¸åº”ç…§ç‰‡ï¼Œå°±ä¼šé¿å…é”™è¯¯çš„è¯†åˆ«ã€‚
2. ä¿®æ”¹å‚æ•°ï¼Œå¯ä»¥ç»“åˆæœ€å¤§ä¼¼ç„¶ä¼°è®¡é€‰æ‹©åˆé€‚çš„å‚æ•°ã€‚ 


### 4.2  æ”¶è·

åœ¨è¾¹å­¦è¾¹åšçš„è¿‡ç¨‹ä¸­ï¼Œäº†è§£è§†é¢‘ä¸å›¾ç‰‡å¤„ç†æ–¹æ³•å’Œæ¦‚å¿µã€‚ç«™åœ¨å·¨äººçš„è‚©è†€ä¸Šï¼Œåˆ©ç”¨å·²ç»æœ‰çš„è½®å­å®ç°ã€‚ä½†æ˜¯ä¹Ÿä¸èƒ½æ²‰æµ¸äºæ­¤ï¼Œè¿˜æ˜¯è¦å¢å¼ºç»Ÿè®¡ç›¸å…³çš„çŸ¥è¯†ã€‚

æœ€åï¼Œåœ¨æ­¤è®°å½•å®ç°è¿‡ç¨‹ï¼Œä¾¿äºåç»­å‚è€ƒã€‚å¹¶ä¸”è®°å½•é‡åˆ°é—®é¢˜ä»¥åŠè§£å†³åŠæ³•ã€‚ 

å¦‚æœä½ çœ‹åˆ°è¿™ï¼Œå°±è®©æˆ‘ä¸ºä½ æ”¾ä¸€é¦–æ­Œå§ï¼Œç¥ä½ ç”Ÿæ´»æ„‰å¿« ï¼ ğŸ˜œ

<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=100% height=86 src="//music.163.com/outchain/player?type=2&id=536098119&auto=0&height=66"></iframe>




### å‚è€ƒé“¾æ¥ 

1. [**Pyimage**](pyimagesearch.com/2018/06/18/face-recognition-with-opencv-python-and-deep-learning/)




